from openai import OpenAI
import whisper
import os

model = whisper.load_model("tiny")

def transcribe_audio(filename: str, language: str = "he") -> dict:
    filename = str(filename)
    if not os.path.exists(filename):
        raise FileNotFoundError(f"‚ö†Ô∏è Audio file not found: {filename}")
    
    print(f"üß† audio file for transcription: {filename}")
    
    try:
        result = model.transcribe(filename, language=language)
    except Exception as e:
        raise RuntimeError(f"‚ùå Whisper transcription failed: {e}")
    
    print("‚úÖ Transcription complete")
    # print(result)
    return {
        "text": result["text"],
        "segments": [
            {
                "id": s["id"], 
                "start": s["start"], 
                "end": s["end"], 
                "text": s["text"]
            }
            for s in result["segments"]
        ]
    }
